# Enter Fellowship ‚Äì Extra√ß√£o Inteligente Progressiva de Documentos

Sistema h√≠brido de extra√ß√£o estruturada de PDFs que combina heur√≠sticas r√°pidas, Machine Learning local e fallback inteligente via LLM, com forte foco em custo m√≠nimo e lat√™ncia previs√≠vel.

## Objetivo

Extrair campos estruturados (ex.: nome, CPF, data de validade, categoria, endere√ßo) de documentos PDF heterog√™neos com:

- Baixo custo (LLM s√≥ em √∫ltimo caso)
- Alta reutiliza√ß√£o (cache multi-camada + reutiliza√ß√£o por campo)
- Evolu√ß√£o incremental de schemas sem reprocessar tudo

## Desafios Mapeados

| Desafio                                            | Por que √© dif√≠cil                                          | Decis√£o                                                 | Estado                                            |
| -------------------------------------------------- | ---------------------------------------------------------- | ------------------------------------------------------- | ------------------------------------------------- |
| Identificar campos com formato r√≠gido (CPF, datas) | F√°cil por regex, mas misturados em texto sujo              | Regex + normaliza√ß√£o                                    | Resolvido                                         |
| Campos sem padr√£o (nome, endere√ßo, √≥rg√£o emissor)  | N√£o funciona bem com regex                                 | Embeddings + n-grams + similaridade                     | Resolvido                                         |
| Baixa precis√£o e lentid√£o do few/zero-shot puro    | Alto custo e baixa taxa de acerto em portugu√™s misto       | Substitu√≠do por mini-modelo de embeddings multil√≠ngue   | Resolvido                                         |
| Polui√ß√£o textual (labels confundindo valores)      | Modelo retorna a pr√≥pria label em vez do valor             | Remo√ß√£o heur√≠stica + detec√ß√£o sem√¢ntica de labels       | Parcial (label detection integrada em background) |
| Evitar reprocessamento quando schema muda          | Novos campos sobre mesmo PDF                               | Cache por campo + merge incremental                     | Resolvido                                         |
| Reduzir custo GPT                                  | LLM devolvendo dados j√° √≥bvios                             | Pipeline progressivo (Cache ‚Üí Regex ‚Üí Embeddings ‚Üí GPT) | Resolvido                                         |
| Escala em lote com feedback                        | Processar centenas de PDFs sem bloquear UI                 | SSE streaming + job state interno                       | Resolvido                                         |
| Persist√™ncia distinta: vol√°til vs hist√≥rica        | Misturar itens ef√™meros com hist√≥rico degrada consist√™ncia | Dois Redis: cache (LRU) e storage (dur√°vel)             | Resolvido                                         |
|                                                    |

## Solu√ß√µes Aplicadas

- Hash de conte√∫do (SHA256) para endere√ßar PDF de forma idempotente independentemente de nome de arquivo.
- Cache multi-camada (resultado completo, campo isolado, texto bruto).
- Remo√ß√£o seletiva de labels/keywords para reduzir ru√≠do sem apagar valores candidatos.
- N-grams adaptativos (1‚Äì5 tokens) gerando janelas sem√¢nticas leves para similaridade.
- Fallback GPT depois de regex com campos n√∫mericos, datas, padr√µes
- Detec√ß√£o ass√≠ncrona de labels (fire-and-forget) preparando terreno para limpeza ainda mais precisa em futuras requisi√ß√µes.
- Stream SSE para batch jobs: progressivo, item-complete, resumo final.
- Versionamento autom√°tico de schemas para rastreabilidade de evolu√ß√£o e compara√ß√£o de acur√°cia.

## Arquitetura

```
Cliente (Next.js) ‚Üí API .NET (8080) ‚Üí Redis Cache (6379) / Redis Storage (6380)
															‚Üò
															 Python FastAPI (5000) ‚Üí Embeddings / NER / Fallback GPT
```

Dois Redis distintos:

- Cache (LRU, sem persist√™ncia) para velocidade;
- Storage (RDB + AOF) para hist√≥rico, schemas, estat√≠sticas e rastreabilidade.

## Fluxo Simplificado

1. Recebe requisi√ß√£o com label + schema + PDF (base64).
2. Calcula pdfHash ‚Üí tenta cache completo.
3. Se falhar, busca valores j√° extra√≠dos campo a campo (cache parcial).
4. Aplica Regex/Enum para campos formais ‚Üí remove valores do texto residual.
5. Limpa labels/keywords ‚Üí gera n-grams ‚Üí similaridade embeddings.
6. Campos abaixo do threshold ‚Üí Fallback GPT (modelo econ√¥mico).
7. Merge final + salvamento multi-camada + hist√≥rico.
8. Dispara detec√ß√£o sem√¢ntica de labels em background.

## Como Usar (Quick Start)

OBS: Pode demorar subir pois h√° alguns modelos de NLP que s√£o instalados durante o processo


### 1. Pr√©-requisitos

- Docker
- Docker Compose
- Git

### 2. Clonar

```bash
git clone https://github.com/davibasa/Enter_Fellowship.git
cd Enter_Fellowship
```

### 3. Subir stack

Alterar OPENAI_API_KEY no docker-compose.yml na se√ß√£o do BACKEND PYTHON:

```dockerfile
environment:
      - REDIS_CACHE_URL=redis://redis-cache:6379/0
      - REDIS_STORAGE_URL=redis://redis-storage:6379/0
      - OPENAI_API_KEY=API_KEY
```

```powershell
docker compose up -d
```

Servi√ßos principais:

- API .NET: http://localhost:8080
- Frontend: http://localhost:3000
- Python FastAPI: http://localhost:5000
- Redis Commander: http://localhost:8082

### 5. Verificar sa√∫de

```
GET http://localhost:5000/health
GET http://localhost:8080/health (se exposto)
```

### 6. Extra√ß√£o simples

```http
POST http://localhost:8080/api/extractor
Content-Type: application/json

{
	"label": "CNH",
	"pdfBase64": "JVBERi0xLjQK...",
	"extractionSchema": {
		"nome": "Nome completo",
		"cpf": "Cadastro de Pessoa F√≠sica",
		"categoria": "Categoria da CNH (pode ser A, B, C, D, E, AB)"
	}
}
```

### 7. Exemplo de resposta

```json
{
  "schema": {
    "nome": "Jo√£o Silva",
    "cpf": "123.456.789-10",
    "categoria": "AB"
  },
  "processingTimeMs": 274,
  "confidence": 0.93,
  "cache": {
    "hitType": "partial"
  }
}
```

### 8. Processamento em lote (SSE)

1. `POST /api/extractor/batch` ‚Üí retorna `jobId`.
2. Abrir stream: `GET /api/extractor/batch/{jobId}/stream`.
3. Eventos: `progress`, `item-complete`, `complete`.

## Estrat√©gia de Qualidade

- Reutiliza√ß√£o de valores evita diverg√™ncia entre execu√ß√µes.
- Hash garante idempot√™ncia.
- Pr√≥ximo passo: testes unit√°rios de classificadores e m√≥dulo de merge.

## Seguran√ßa & Resili√™ncia (Atual / Planejado)

- CORS configurado.
- Dois n√≠veis de armazenamento Redis separados (menor risco de polui√ß√£o de dados).
- Planejado: Rate limiting, retry com jitter para lote, circuit breaker em chamadas externas (Python/LLM), valida√ß√£o de schema via FluentValidation.

## üî≠ Roadmap Resumido

Curto prazo:

- Integrar texto limpo via label detection no fluxo principal.
- M√©tricas (Prometheus + OpenTelemetry).
- Valida√ß√£o de schema.
- Retry em lote.

M√©dio prazo:

- Rate limiting.
- Health check profundo Python (modelo carregado, Redis acess√≠vel, tempo de embedding).
- Otimiza√ß√£o sem√¢ntica de remo√ß√£o de keywords (stop words + padr√µes).

Longo prazo:

- Sele√ß√£o adaptativa de modelos GPT.
- Dashboard Grafana + alertas.
- Circuit breaker.
- Escalar FastAPI (Gunicorn + workers / async pool).

## Decis√µes de Design (Resumo Explicativo)

- ‚ÄúProgressive Intelligence‚Äù: cada camada s√≥ acontece se a anterior falhar ‚Üí evita desperd√≠cio.
- Separa√ß√£o cache vs storage: performance vs consist√™ncia hist√≥rica.
- Embeddings mini multil√≠ngue: balan√ßo ideal entre velocidade e sem√¢ntica em PT/EN/ES.
- Fire-and-forget para label detection: prepara futuras otimiza√ß√µes sem adicionar lat√™ncia ao caminho cr√≠tico.
- Remo√ß√£o de ru√≠do antes de ML reduz tokens e eleva precis√£o evitando eco de labels.

## Conceitos Aplicados

- Similaridade coseno em espa√ßo de embeddings.
- N-grams din√¢micos para granularidade vari√°vel.
- Content-based addressing via hash SHA256.
- SSE para feedback cont√≠nuo sem WebSockets.
- Multi-cache: compartilhamento de fragmentos de resultado entre schemas evolutivos.
